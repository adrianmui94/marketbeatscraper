{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MarketBeat Analyst Rating Scraper \n",
    "\n",
    "Iterates through the stock analyst upgrades/downgrades on [marketbeat.com](https://www.marketbeat.com/ratings/) by day and scrapes them into .csv file.\n",
    "\n",
    "Historical analyst data can be used to look into whether or not following these calls have an edge, and whether not one analyst group is more credible than another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import common libraries \n",
    "\n",
    "# Assert selenium chromedriver is up to date\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Web scraping libraries \n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.keys import Keys \n",
    "\n",
    "# BeautifulSoup \n",
    "import bs4 \n",
    "\n",
    "# Data analysis libraries \n",
    "# import numpy as np \n",
    "# import pandas as pd \n",
    "# import matplotlib.pyplot as plt \n",
    "\n",
    "# Common libraries \n",
    "import os \n",
    "from pprint import pprint \n",
    "from tqdm import tqdm\n",
    "import datetime as dt \n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close popup window if it comes up \n",
    "def handle_first_popup():\n",
    "    if wb.find_element_by_id('optinform-modal'):\n",
    "        wb.find_element_by_class_name('x').click()\n",
    "\n",
    "# Close some other popup which can show up sometimes\n",
    "def handle_other_popup():\n",
    "    try:\n",
    "        if wb.find_element_by_xpath('//*[@id=\"optinform-modal\"]/div/span'):\n",
    "            wb.find_element_by_xpath('//*[@id=\"optinform-modal\"]/div/span').click()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_date(date):\n",
    "    '''\n",
    "    Changes the date on the analyst website for Marketbeat.\n",
    "    This is necessary because using clearing the datefield with clear() will reset to the previous date \n",
    "    since there is no cursor inside the field.\n",
    "    --------------------------------------------------------------------------------------------------\n",
    "    INPUT:\n",
    "    date - the date in either datetime or string format\n",
    "    \n",
    "    \n",
    "    OUTPUT:\n",
    "    None\n",
    "    '''\n",
    "    if type(date) == type(dt.datetime.today().date()):\n",
    "        date = date.strftime('%m/%d/%Y')\n",
    "    # Submitting date information \n",
    "\n",
    "    # Click on the date field\n",
    "    date_field = wb.find_element_by_name('ctl00$cphPrimaryContent$txtStartDate')\n",
    "    date_field.click()\n",
    "\n",
    "    # Backspace the current date \n",
    "    for _ in range(11):\n",
    "        webdriver.ActionChains(wb).send_keys(Keys.BACKSPACE).perform()\n",
    "\n",
    "    # Send a new date\n",
    "    date_field.send_keys(date)\n",
    "    webdriver.ActionChains(wb).send_keys(Keys.ENTER).perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Example Output To Export to CSV\n",
    "| Date       | Company | Action  | Brokerage | PT1 | PT2 | Rating | Impact |\n",
    "|------------|---------|---------|-----------|-----|-----|--------|--------|\n",
    "| 10/08/2020 | AAPL    | Upgrade | JPM       | 100 | 130 | Buy    | Medium |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_values(html):\n",
    "    '''\n",
    "    Pulls the tabular analyst data from the current marketbeat analyst page using BeautifulSoup4\n",
    "    --------------------------------------------------------------------------------------------------\n",
    "    INPUT:\n",
    "    html - Can be from selenium page source or via requests.\n",
    "    \n",
    "    OUTPUT:\n",
    "    scraped - 2D array of scraped values.\n",
    "    '''\n",
    "    scraped = []\n",
    "    soup = bs4.BeautifulSoup(html)\n",
    "    \n",
    "    # The rows of the table are enclosed within the 'tr' tag.\n",
    "    table_rows =  soup.find_all('tr')\n",
    "    \n",
    "    # Iterate through the rows of the table, ignoring the header\n",
    "    for row in table_rows[1:]:\n",
    "        \n",
    "        # Grab the ticker & company name\n",
    "        try:\n",
    "            ticker = row.select('.ticker-area')[0].text.strip().upper()\n",
    "            company_name = row.select('.title-area')[0].text.strip().upper()\n",
    "        \n",
    "        # One row in this table is always an ad (?)\n",
    "        except IndexError:\n",
    "            continue\n",
    "        \n",
    "        # The remaining columns do not have unique names and are enclosed in the 'td' tag\n",
    "        # The first td tag includes the things scraped above, so we ignore it\n",
    "        action_description = row.find_all('td')[1:]\n",
    "        \n",
    "        # Clean the list of their tags\n",
    "        cleaned = list(map(lambda x: x.text.strip(), action_description))[:-1] # Last item is useless\n",
    "        del cleaned[2] # Current price is useless\n",
    "        \n",
    "        # Extract 0, 1, or 2 price targets\n",
    "        clean_targets = handle_price_targets(cleaned[2]) \n",
    "        \n",
    "        # Extract 1 or 2 price targets\n",
    "        clean_ratings = handle_ratings(cleaned[-2])\n",
    "        \n",
    "        # Formatted row for appending to master rows\n",
    "        scraped_row = [page_date_str, ticker, company_name] + cleaned[:2] + clean_targets + clean_ratings + [cleaned[-1]]\n",
    "        scraped.append(scraped_row)\n",
    "    return scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_price_targets(price_target):\n",
    "    '''\n",
    "    Marketbeat price target column can be empty, have one number, or two numbers.\n",
    "    Use this function to return all the numbers in separate columns.\n",
    "    --------------------------------------------------------------------------------------------------\n",
    "    INPUT:\n",
    "    price_target - string, targets in the format $\\d\\d.\\d\\d. Can include a '➝' character indicating a price change.\n",
    "    \n",
    "    OUTPUT:\n",
    "    clean_targets - list of 2 floats or Nones. The previous price target and the new one.\n",
    "    '''\n",
    "    # Remove impurities \n",
    "    price_target = price_target.replace('$', '').replace(',', '')\n",
    "    price_target = price_target.replace('(', '').replace(')', '')\n",
    "    \n",
    "    # Case 1: The field is blank.\n",
    "    if price_target == '':\n",
    "        clean_targets = [None, None]\n",
    "    \n",
    "    # Case 2: The price target has changed and is indicated by an arrow\n",
    "    elif '➝' in price_target:\n",
    "        clean_targets = price_target.split('➝')\n",
    "        clean_targets = [float(ct.strip()) for ct in clean_targets]\n",
    "    \n",
    "    else:\n",
    "        clean_targets = [None, float(price_target.strip())]\n",
    "    \n",
    "    return clean_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_ratings(ratings):\n",
    "    '''\n",
    "    Marketbeat upgrades/downgrades show a change of rating (e.g. Neutral ➝ Outperform) or just have a single\n",
    "    rating present (Neutral)\n",
    "    Use this function to grab one or both actions.\n",
    "    --------------------------------------------------------------------------------------------------\n",
    "    INPUT:\n",
    "    ratings - string, either has 0, 1, or 2 ratings\n",
    "    \n",
    "    OUTPUT:\n",
    "    clean_ratings - list containing two different ratings, or one None and one rating.\n",
    "    '''\n",
    "    ratings = ratings.split('➝')\n",
    "    if len(ratings) == 2:\n",
    "        ratings = [rating.strip().upper() for rating in ratings]\n",
    "    else:\n",
    "        ratings = [None, ratings[0].upper()]\n",
    "        if ratings[1] == '': ratings[1] = None\n",
    "    \n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program Begins Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a market beat data file does not exist\n",
    "# If it doesn't, make one\n",
    "file_list = os.listdir()\n",
    "if 'marketbeat_analyst_data.csv' not in file_list:\n",
    "    with open('marketbeat_analyst_data.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['date', 'ticker', 'company', 'action', 'brokerage', 'pt1', 'pt2', 'rating1', 'rating2', 'impact'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 86.0.4240\n",
      "[WDM] - Get LATEST driver version for 86.0.4240\n",
      "[WDM] - There is no [win32] chromedriver for browser 86.0.4240 in cache\n",
      "[WDM] - Get LATEST driver version for 86.0.4240\n",
      "[WDM] - Trying to download new driver from http://chromedriver.storage.googleapis.com/86.0.4240.22/chromedriver_win32.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver has been saved in cache [C:\\Users\\mui\\.wdm\\drivers\\chromedriver\\win32\\86.0.4240.22]\n"
     ]
    }
   ],
   "source": [
    "# Instatiate a webdriver object \n",
    "wb = webdriver.Chrome(ChromeDriverManager().install())\n",
    "url = 'https://www.marketbeat.com/ratings/'\n",
    "\n",
    "# Navigate to the url \n",
    "wb.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of the first popup\n",
    "handle_first_popup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click dropdown to only allow US stocks\n",
    "country_selector = wb.find_element_by_name('ctl00$cphPrimaryContent$ddlCountry')\n",
    "country_selector.click()\n",
    "\n",
    "#Click 'United States'\n",
    "country_selector.find_element_by_xpath('//*[@id=\"cphPrimaryContent_ddlCountry\"]/option[2]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "# Find out how many dates have been scraped already\n",
    "# Prevents issues if exceptions occur mid scrape\n",
    "with open('marketbeat_analyst_data.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    completed_dates = [row[0] for row in list(reader)[1:]]\n",
    "completed_dates = set(completed_dates)\n",
    "\n",
    "# Arbitrary start time. To be user input.\n",
    "start_date_dt = dt.datetime(year=2015, month=1, day=1).date()\n",
    "start_date_str = start_date_dt.strftime('%m/%d/%Y')\n",
    "\n",
    "page_date = start_date_dt\n",
    "\n",
    "while page_date != (dt.datetime.today().date() + dt.timedelta(days=1)):\n",
    "    # Handle weekends\n",
    "    if page_date.strftime('%A') in ['Saturday', 'Sunday']:\n",
    "        page_date += dt.timedelta(days=1)\n",
    "        continue\n",
    "        \n",
    "    # Use try/except to deal with selenium issues \n",
    "    # i.e. page loading too fast and elements not loading\n",
    "    try:\n",
    "        page_date_str = page_date.strftime('%m/%d/%Y')\n",
    "        if page_date_str in completed_dates:\n",
    "            page_date += dt.timedelta(days=1)\n",
    "            continue\n",
    "\n",
    "        change_date(page_date)\n",
    "        time.sleep(1.5)\n",
    "        scraped = scrape_values(wb.page_source)\n",
    "    \n",
    "    except:\n",
    "        # Close other popup if exists\n",
    "        handle_other_popup()\n",
    "        time.sleep(3)\n",
    "        continue\n",
    "        \n",
    "    # Create a file to save your analyst ratings if one doesn't exist\n",
    "    if scraped != []:\n",
    "        with open('marketbeat_analyst_data.csv', 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f, delimiter = ',')\n",
    "            for row in scraped:\n",
    "                writer.writerow(row)\n",
    "    \n",
    "    # Increment by 1 day after completion\n",
    "    page_date += dt.timedelta(days=1)\n",
    "    \n",
    "print('Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
